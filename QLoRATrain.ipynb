{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install -U bitsandbytes\n","!pip install -U transformers\n","!pip install -U peft\n","!pip install -U accelerate\n","!pip install -U trl \n","!pip install -q datasets\n","!pip install -q einops wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install trl"]},{"cell_type":"markdown","metadata":{},"source":["# Imports and downloading data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:27:19.371528Z","iopub.status.busy":"2024-06-04T18:27:19.371224Z","iopub.status.idle":"2024-06-04T18:27:29.340439Z","shell.execute_reply":"2024-06-04T18:27:29.339230Z","shell.execute_reply.started":"2024-06-04T18:27:19.371499Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n","import os,torch, wandb\n","from datasets import load_dataset\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:27:43.326169Z","iopub.status.busy":"2024-06-04T18:27:43.325745Z","iopub.status.idle":"2024-06-04T18:28:33.859481Z","shell.execute_reply":"2024-06-04T18:28:33.858420Z","shell.execute_reply.started":"2024-06-04T18:27:43.326111Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"teknium/OpenHermes-2.5\", split=\"train\")"]},{"cell_type":"markdown","metadata":{},"source":["Preparing dataset for train "]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:08:46.979109Z","iopub.status.busy":"2024-06-04T19:08:46.978197Z","iopub.status.idle":"2024-06-04T19:08:46.984071Z","shell.execute_reply":"2024-06-04T19:08:46.982843Z","shell.execute_reply.started":"2024-06-04T19:08:46.979053Z"},"trusted":true},"outputs":[],"source":["EOS_TOKEN = tokenizer.eos_token "]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:08:52.494211Z","iopub.status.busy":"2024-06-04T19:08:52.493460Z","iopub.status.idle":"2024-06-04T19:08:52.501178Z","shell.execute_reply":"2024-06-04T19:08:52.500136Z","shell.execute_reply.started":"2024-06-04T19:08:52.494165Z"},"trusted":true},"outputs":[],"source":["def formatting_prompts_func(examples):\n","    convos = examples[\"conversations\"]\n","    texts = []\n","    mapper = {\"system\" : \"<|im_start|>system\\n\", \"human\" : \"\\n<|im_start|>user\\n\", \"gpt\" : \"\\n<|im_start|>assistant\\n\"}\n","    end_mapper = {\"system\" : \"<|im_end|>\", \"human\" : \"<|im_end|>\", \"gpt\" : \"<|im_end|>\"}\n","    for convo in convos:\n","        text = \"\".join(f\"{mapper[(turn := x['from'])]} {x['value']}\\n{end_mapper[turn]}\" for x in convo)\n","        texts.append(f\"{text}{EOS_TOKEN}\") # Since there are multi-turn\n","        # conversations, I append the EOS_TOKEN at the end of the whole\n","        # conversation. These conversations always ends with a gpt message.\n","    return { \"text\" : texts, }\n","pass"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:11:58.138192Z","iopub.status.busy":"2024-06-04T19:11:58.136972Z","iopub.status.idle":"2024-06-04T19:11:58.144770Z","shell.execute_reply":"2024-06-04T19:11:58.143649Z","shell.execute_reply.started":"2024-06-04T19:11:58.138148Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","<|im_start|>user\n"," Every day, a tree drops 7 leaves. How many leaves would it drop in a month of February in a non-leap year? Include your logic.\n","<|im_end|>\n","<|im_start|>assistant\n"," Here's the logic behind this:\n","\n","1. We know that February has 28 days in a non-leap year.\n","2. If the tree drops 7 leaves every day, then over the course of February, it would drop:\n","   Leaves dropped in February = Leaves per day * Days in February\n","   = 7 leaves * 28 days\n","   = 196 leaves\n","\n","So, the tree would drop 196 leaves in February in a non-leap year.\n","<|im_end|></s>\n"]}],"source":["print((formatting_prompts_func(dataset[0:3])['text'][0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:12:30.613279Z","iopub.status.busy":"2024-06-04T19:12:30.612715Z","iopub.status.idle":"2024-06-04T19:13:35.442766Z","shell.execute_reply":"2024-06-04T19:13:35.441611Z","shell.execute_reply.started":"2024-06-04T19:12:30.613229Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.map(formatting_prompts_func, batched = True,)\n","print(dataset['text'][8])"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:14:53.334796Z","iopub.status.busy":"2024-06-04T19:14:53.334382Z","iopub.status.idle":"2024-06-04T19:14:53.342339Z","shell.execute_reply":"2024-06-04T19:14:53.341129Z","shell.execute_reply.started":"2024-06-04T19:14:53.334764Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source', 'text'],\n","    num_rows: 1001551\n","})"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:36:19.098950Z","iopub.status.busy":"2024-06-04T18:36:19.097779Z","iopub.status.idle":"2024-06-04T18:36:19.103566Z","shell.execute_reply":"2024-06-04T18:36:19.102523Z","shell.execute_reply.started":"2024-06-04T18:36:19.098908Z"},"trusted":true},"outputs":[],"source":["access_token = \"??????\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:53:56.530621Z","iopub.status.busy":"2024-06-04T18:53:56.530193Z","iopub.status.idle":"2024-06-04T18:54:15.862319Z","shell.execute_reply":"2024-06-04T18:54:15.861125Z","shell.execute_reply.started":"2024-06-04T18:53:56.530587Z"},"trusted":true},"outputs":[],"source":["model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    trust_remote_code=True, \n","    token = access_token\n",")\n","\n","model.config.use_cache = False\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, token = access_token)\n","tokenizer.padding_side = 'right'"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:41:26.815780Z","iopub.status.busy":"2024-06-04T18:41:26.815467Z","iopub.status.idle":"2024-06-04T18:41:26.826087Z","shell.execute_reply":"2024-06-04T18:41:26.825016Z","shell.execute_reply.started":"2024-06-04T18:41:26.815753Z"},"trusted":true},"outputs":[{"data":{"text/plain":["MistralForCausalLM(\n","  (model): MistralModel(\n","    (embed_tokens): Embedding(32768, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x MistralDecoderLayer(\n","        (self_attn): MistralSdpaAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): MistralRotaryEmbedding()\n","        )\n","        (mlp): MistralMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): MistralRMSNorm()\n","        (post_attention_layernorm): MistralRMSNorm()\n","      )\n","    )\n","    (norm): MistralRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{},"source":["# Train config"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:43:00.237458Z","iopub.status.busy":"2024-06-04T18:43:00.237014Z","iopub.status.idle":"2024-06-04T18:43:00.243519Z","shell.execute_reply":"2024-06-04T18:43:00.242200Z","shell.execute_reply.started":"2024-06-04T18:43:00.237426Z"},"trusted":true},"outputs":[],"source":["lora_alpha = 16\n","lora_dropout = 0.1\n","lora_r = 64\n","\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=lora_r,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:46:15.848340Z","iopub.status.busy":"2024-06-04T18:46:15.847862Z","iopub.status.idle":"2024-06-04T18:47:57.684333Z","shell.execute_reply":"2024-06-04T18:47:57.683191Z","shell.execute_reply.started":"2024-06-04T18:46:15.848303Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T18:48:09.324427Z","iopub.status.busy":"2024-06-04T18:48:09.323984Z","iopub.status.idle":"2024-06-04T18:48:09.364112Z","shell.execute_reply":"2024-06-04T18:48:09.362708Z","shell.execute_reply.started":"2024-06-04T18:48:09.324393Z"},"trusted":true},"outputs":[],"source":["output_dir = \"./results\"\n","per_device_train_batch_size = 4\n","gradient_accumulation_steps = 4\n","optim = \"paged_adamw_32bit\"\n","save_steps = 100\n","logging_steps = 10\n","learning_rate = 2e-4\n","max_grad_norm = 0.3\n","max_steps = 100\n","warmup_ratio = 0.03\n","lr_scheduler_type = \"constant\"\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    save_steps=save_steps,\n","    logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    fp16=True,\n","    max_grad_norm=max_grad_norm,\n","    max_steps=max_steps,\n","    warmup_ratio=warmup_ratio,\n","    group_by_length=True,\n","    lr_scheduler_type=lr_scheduler_type,\n","    \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-04T19:15:03.042351Z","iopub.status.busy":"2024-06-04T19:15:03.041906Z"},"trusted":true},"outputs":[],"source":["max_seq_length = 512\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=peft_config,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, module in trainer.model.named_modules():\n","    if \"norm\" in name:\n","        module = module.to(torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(\"outputs\")\n","lora_config = LoraConfig.from_pretrained('outputs')\n","model = get_peft_model(model, lora_config)"]},{"cell_type":"markdown","metadata":{},"source":["# Benchmark"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lora_config = LoraConfig.from_pretrained('outputs')\n","model = get_peft_model(model, lora_config)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
